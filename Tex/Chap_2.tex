\chapter{分布式大数据内存计算系统Spark系统实现机制概述}\label{chap:basic}
\section{Spark系统实现概述概述}
Spark是一种基于内存的分布式计算框架。Spark框架分为四层：用户层、作业管理执行层、资源任务调度层、物理执行层。在用户层，用户需要使用框架api编写应用代码，准备输入数据，配置应用参数。用户将这些信息提交给作业管理执行层后，框架会将用户应用转化为具体的作业执行计划，分为逻辑处理计划（数据单元和数据处理依赖关系）和物理执行计划（具体执行计划和阶段）。生成了具体的执行计划之后，框架的资源任务调度层会向集群资源管理器申请资源，资源申请成功后，框架把具体任务和资源绑定，并发送作业执行计划给物理执行层。物理执行层收到作业执行计划之后，会根据作业的配置信息下载应用代码，运行任务并将执行结果反馈给框架。下面会对Spark框架的四层进行进一步的介绍。

\begin{enumerate}
    \item 用户层：用户层提供了丰富的应用接口。包括面向结构化数据的查询接口Spark SQL，面向图计算的GraphX、面向机器学习的Spark MLlib，面向实时流计算的Spark Stream。用户使用提供的接口可以实现丰富的应用程序。
    \item 作业管理执行层：框架收到用户提交的应用程序后，就将其解析成Spark可以识别的逻辑执行计划。比如对于Spark SQL作业，会通过SQL语言的解释器将SQL语句解释为Spark可识别的作业执行计划，一般是以DAG（Directed Acycilc Graph）有向无环图结构组成的作业执行计划。Spark框架会遍历DAG，如果遇到需要Shuffle的边就会对当前边进行切割。遍历完毕之后整个DAG被切割成多个子图，每个子图都会更具拓扑顺序从前到后逐渐调度执行。
    \item 资源任务调度层：Spark框架一般是主从（Master-Slave）架构。主节点负责接受用户的应用，解析作业，管理执行作业，并在出错场景下做容错管理。从节点主要负责接受主节点的任务执行计划，具体执行作业并将结果汇总给主节点。
    \item 物理执行层：
\end{enumerate}

\section{Spark系统整体架构}
\section{分布式内存计算核心模块分析}
\subsection{分布式弹性数据集RDD}
\subsection{作业执行调度模块}
\subsection{缓存数据管理模块}
\section{缓存管理模块分析}
\subsection{Shuffle缓存}
\subsection{Storage缓存}
\subsection{Unroll缓存}
\section{本章总结}





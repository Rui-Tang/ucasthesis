\chapter{Spark自动缓存模块设计与实现}\label{chap:auto-cache}

\section{Spark缓存现状分析}
Spark框架相对于Hadoop的核心改进是添加了缓存管理模块。通过将计算过程中的中间数据缓存在内存中可以极大的加速计算过程。尤其对于机器学习和图计算等迭代式计算有上百倍的加速效果。这是因为这种迭代式计算需要多次重复访问中间数据，就非常能体现Spark框架的优势。

Spark应用在执行过程中会将应用程序解析成DAG图，然后根据DAG的拓扑排序顺序执行DAG图中的每一个操作。一个RDD数据被计算得到之后，会存放在Execution Memory区域。如果没有立即被使用使用到就会从Execution Memory区域被删除。Spark框架给应用程序员提供了cache接口，cache接口会将RDD对象的STORAGE\_LEVEL字段标记为MEMORY\_ONLY。标记之后Spark框架并不会立即缓存数据，而是在RDD分区数据计算完成时查看STORAGE\_LEVEL标记。根据不同的标记将数据缓存到不同的位置，常见的标记有以下几种，MEMORY\_ONLY，DISK\_ONLY，MEMORY\_AND\_DISK。如果标记为MEMORY\_ONLY框架就会将数据缓存到内存之中，具体过程是将RDD的应用发送给BlockManager对象的MemoryStore模块。MemoryStore模块会保存RDD模块的引用。这样就能将RDD对象长时间保存在内存中。从缓存管理模块的逻辑视图角度来看cache接口调用是将RDD对象从Execution Memory区域移到了Storage Memory区域。如果STORAGE\_LEVEL标记为DISK\_ONLY。框架会将RDD对象的引用发送给BlockManager的DiskStore模块。DiskStore模块在HDFS或者其他文件系统上创建一个文件，将RDD对象写入文件之中。并且保存文件的路径。这就是缓存管理模块的核心过程。

当要使用到一个RDD数据时，框架会从BlockManager模块查看数据是否存在缓存数据。此时有两种情况，如果缓存数据存放在磁盘之中框架会将数据读取加载到内存的Execution Memory区域。如果是缓存在内存之中就可以直接进行计算。

在分析了缓存模块的核心原理之后还有一个重要的问题，就是缓存决策是如何实现的。目前Spark应用的缓存决策全都由编程人员在开发的过程中手动指定。这存在着几个问题。第一，编程人员可能会做出不正确的缓存决定，缓存了无用的数据，这会导致内存被浪费，降低了系统内存资源的使用效率。第二，编程人员可能没有缓存重要数据，导致在计算的过程中重复计算重要数据，对应用程序的执行时间造成巨大的影响。第三，这种编程模式对Spark应用编程人员提出了比较高的要求，编程人员必须熟悉Spark框架的核心原理，还要熟悉Spark提供的众多算子的底层实现，在此基础上还需要在编程的过程中选择合适的数据进行缓存，在Spark应用程序规模变大之后就会对编程人员造成比较大的负担。

同时还需要考虑Spark框架最新的动态执行新特性。Spark框架本身是在不断发展之中，Spark这类并行数据处理系统存在着数据倾斜的问题。

综合考虑背景以及这些问题，本章就提出了一种改进的自动缓存方法。可以自动分析Spark应用程序中需要缓存的数据，并且

\section{自动缓存模块}
\subsection{改进版基于二次执行的自动缓存模块设计}
\subsection{自动缓存模块实现}
\section{自动缓存管理模块测试与性能分析}
\section{本章总结}



\chapter{Spark自动缓存模块设计与实现}\label{chap:auto-cache}

\section{Spark缓存现状分析}
Spark框架相对于Hadoop的核心改进是添加了缓存管理模块。通过将计算过程中的中间数据缓存在内存中可以极大的加速计算过程。尤其对于机器学习和图计算等迭代式计算有上百倍的加速效果。这是因为这种迭代式计算需要多次重复访问中间数据，就非常能体现Spark框架的优势。

Spark应用在执行过程中会将应用程序解析成DAG图，然后根据DAG的拓扑排序顺序执行DAG图中的每一个操作。一个RDD数据被计算得到之后，会存放在Execution Memory区域。如果没有立即被使用使用到就会从Execution Memory区域被删除。Spark框架给应用程序员提供了cache接口，cache接口会将RDD对象的STORAGE\_LEVEL字段标记为MEMORY\_ONLY。标记之后Spark框架并不会立即缓存数据，而是在RDD分区数据计算完成时查看STORAGE\_LEVEL标记。根据不同的标记将数据缓存到不同的位置，常见的标记有以下几种，MEMORY\_ONLY，DISK\_ONLY，MEMORY\_AND\_DISK。如果标记为MEMORY\_ONLY框架就会将数据缓存到内存之中，具体过程是将RDD的应用发送给BlockManager对象的MemoryStore模块。MemoryStore模块会保存RDD模块的引用。这样就能将RDD对象长时间保存在内存中。从缓存管理模块的逻辑视图角度来看cache接口调用是将RDD对象从Execution Memory区域移到了Storage Memory区域。如果STORAGE\_LEVEL标记为DISK\_ONLY。框架会将RDD对象的引用发送给BlockManager的DiskStore模块。DiskStore模块在HDFS或者其他文件系统上创建一个文件，将RDD对象写入文件之中。并且保存文件的路径。这就是缓存管理模块的核心过程。

当要使用到一个RDD数据时，框架会从BlockManager模块查看数据是否存在缓存数据。此时有两种情况，如果缓存数据存放在磁盘之中框架会将数据读取加载到内存的Execution Memory区域。如果是缓存在内存之中就可以直接进行计算。

在分析了缓存模块的核心原理之后还有一个重要的问题，就是缓存决策是如何实现的。目前Spark应用的缓存决策全都由编程人员在开发的过程中手动指定。这存在着几个问题。第一，编程人员可能会做出不正确的缓存觉得，将多余的数据。

\section{自动缓存模块}
\subsection{改进版基于二次执行的自动缓存模块设计}
\subsection{自动缓存模块实现}
\section{自动缓存管理模块测试与性能分析}
\section{本章总结}



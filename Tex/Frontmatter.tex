%---------------------------------------------------------------------------%
%->> Frontmatter
%---------------------------------------------------------------------------%
%-
%-> 生成封面
%-
\maketitle% 生成中文封面
\MAKETITLE% 生成英文封面
%-
%-> 作者声明
%-
\makedeclaration% 生成声明页
%-
%-> 中文摘要
%-
\intobmk\chapter*{摘\quad 要}% 显示在书签但不显示在目录
\setcounter{page}{1}% 开始页码
\pagenumbering{Roman}% 页码符号

计算机的迅速发展与普及使得人民大众也可以享受丰富的计算机应用与产品。为了解决大规模数据处理规模大、速度慢的问题，新型的分布式存储和计算框架应运而生。Spark框架拓展了早期的Hadoop框架，加入了缓存管理机制以及基于弹性分布式数据集RDD（Resilient Distributed Dataset）的丰富并行运算算子。一方面Spark通过基于内存的分布式计算模型支持了图计算、机器学习、大数据等多种应用。此外，Spark解决了传统Hadoop系统计算速度慢，应用场景单一等问题。优化了批处理、交互式处理、迭代式计算等计算模式中存在的重复访问数据的问题。极大的扩展了这类分布式数据处理框架的使用边界。

缓存管理机制和由RDD组成的DAG（Directed Acyclic  Graph）引擎是Spark的核心。但是Spark框架缺乏有效缓存选择机制，框架没有办法识别并缓存计算过程中发生重用的数据。现有Spark缓存框架存在一下三点问题：第一，数据的缓存操作完全依赖于编程人员；第二，Spark框架的缓存管理策略使用了LRU（Least Recent  Use）策略，LRU策略只考虑数据访问的时间信息，没有考虑Spark应用本身的拓扑信息，包括DAG图结构，作业执行时间等信息；第三，因为缓存管理模块依赖于JVM虚拟机，框架和底层JVM内存释放异步执行会造成了潜在的OOM（Out of Memory）问题。

为了解决上述的三个问题。本文在详细研究分析了Spark框架在缓存管理方面的原理和运行机制后，针对Spark的原理设计实现了优化的缓存管理机制，包括：自动缓存管理模块、基于DAG拓扑结构缓存替换策略和容错新加强的冗余缓存清理模块。从而对上述Spark缓存管理机制中存在的三点问题提出了一体化的解决方案。本文的主要工作如下：

\begin{enumerate}
    \item 设计实现自动缓存系统。为了解决手动指定缓存可能导致的错误缓存、操作复杂的问题，该模块通过提前运行小规模数据集得到重复使用的RDD数据，之后再执行大规模数据集时自动缓存重复使用的RDD数据。此外考虑了新版本Spark中添加的动态执行特性。Spark框架在运行过程中修改执行计划时自动管理模块也会实时修改DAG图信息，本文也会相对应的做出调整，保证能够做出正确的缓存决策。通过这种方式实现了自动缓存的功能。经过测试，对于迭代式计算和SQL作业，自动缓存模块平均额外计算开销占作业总执行时间的12\%和3\%。
    \item 设计实现基于DAG拓扑结构的缓存替换策略。为了优化缓存替换策略，从而加速作业执行速度，该策略综合考虑了RDD的大小、计算代价以及DAG图拓扑结构等特征。综合计算得到RDD数据的优先级，发生缓存替换时淘汰优先级最低的RDD数据。经过测试，对于大规模测试样例，作业平均执行时间减少了23s。
    \item 设计实现了容错新增强的冗余缓存清理模块。为了解决缓存占用率高以及出错情况下作业容错性差的问题，该模块通过对DAG图的分析，在计算过程中自动删除部分冗余的缓存对象，提高内存空间利用率。通过保留距离当前正在计算的RDD数据为2的数据，增加了系统的容错性，从而可以兼顾系统的内存利用率和容错性。经过测试，作业执行过程中的缓存占用率平均降低了19.5\%。在容错性测试样例，作业能够迅速恢复计算，整体作业执行时间缩短了27\%。
\end{enumerate}

\keywords{分布式计算，Spark框架，缓存管理，缓存策略}% 中文关键词
%-
%-> 英文摘要
%-
\intobmk\chapter*{Abstract}% 显示在书签但不显示在目录

The rapid development and popularization of computers have enabled the general public to enjoy a wealth of computer applications and products.In order to solve the problem of large-scale data processing, a new type of distributed storage and computing framework came into being.The Spark framework expands the early Hadoop framework, adding a cache management module and a rich operator based on the elastic distributed data set RDD.Spark supports a variety of applications such as graph computing, machine learning, and big data through a memory-based distributed computing model. Spark solves the problems of poor performance of traditional Hadoop systems and single application scenarios thus greatly expand the use boundary of this type of distributed data processing framework.

The cache management module and the DAG engine composed of RDDs are the core optimization points of Spark. However, the Spark framework lacks an effective cache selection mechanism, and the framework cannot identify and cache data that is reused during the calculation process.Data caching operation is completely dependent on the programmer.The cache management strategy of the Spark framework uses a simple LRU strategy. The LRU strategy only considers time information, which does not meet the complex background of Spark applications.Because the cache management module relies on the JVM virtual machine, the asynchronous execution of the framework and the underlying JVM memory release will cause a potential OOM (Out of Memory) problem.

In order to solve the above three problems. This paper studies the principle and operating mechanism of the Spark framework analyzed in detail, and designs and implements an automatic cache management module based on the principle of Spark, a cache replacement strategy based on the DAG topology, and a newly enhanced redundant cache cleaning module for fault tolerance.Thus, a set of solutions are proposed for the problems existing in the Spark cache management system. The main work of this paper is as follows:

\begin{enumerate}
    \item This paper studies and analyzes the design principles and operating mechanisms, resource management methods, and job scheduling operating modes of the distributed memory computing system Spark. This article tests and analyzes the characteristics and problems of Spark's memory management mechanism.This article uses big data benchmark to test the usage characteristics of Execution Memory, Shuffle Memory, and Storage Memory memory partitions in the Spark framework
    \item This article designs and implements an automatic caching system. This article runs a small-scale data set in advance to get the reused RDD data, and then automatically caches the reused RDD data when executing a large-scale data set. This article also considers the dynamic execution features added in the new version of Spark. When the Spark framework modifies the execution plan during the running process, the automatic management module will also modify the DAG graph information in real time. This article ensures that the correct caching decision can be made.
    \item This article designs and implements a cache replacement strategy based on DAG topology. This strategy comprehensively considers the characteristics of RDD size, computational cost, and DAG graph topology structure. The priority of RDD data is obtained by comprehensive calculation, and the RDD data with the lowest priority is eliminated when cache replacement occurs.
    \item This paper designs and implements a new and enhanced redundant cache cleaning module for fault tolerance. Through the analysis of the DAG graph, this article automatically deletes some redundant cache objects during the calculation process to improve the utilization of memory space.This paper increases the fault tolerance of the system by retaining the data whose distance is 2 from the RDD data currently being calculated, so that the memory utilization and fault tolerance of the system can be taken into account.
\end{enumerate}


\KEYWORDS{Distributed computing, Spark framework, cache management, cache strategy}% 英文关键词
%---------------------------------------------------------------------------%

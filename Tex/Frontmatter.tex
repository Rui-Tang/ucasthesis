%---------------------------------------------------------------------------%
%->> Frontmatter
%---------------------------------------------------------------------------%
%-
%-> 生成封面
%-
\maketitle% 生成中文封面
\MAKETITLE% 生成英文封面
%-
%-> 作者声明
%-
\makedeclaration% 生成声明页
%-
%-> 中文摘要
%-
\intobmk\chapter*{摘\quad 要}% 显示在书签但不显示在目录
\setcounter{page}{1}% 开始页码
\pagenumbering{Roman}% 页码符号

计算机的迅速发展与普及使得人民大众也可以享受丰富的计算机应用与产品。为了解决大规模数据处理问题，新型的分布式存储和计算框架应运而生。Spark框架拓展了早期的Hadoop框架，加入了缓存管理模块以及基于弹性分布式数据集RDD的丰富的算子。Spark通过基于内存的分布式计算模型支持了图计算、机器学习、大数据等多种应用。Spark解决了传统Hadoop系统性能差，应用场景单一等问题。优化了批处理、交互式处理、迭代式计算等计算模式中存在的问题。极大的扩展了这类分布式数据处理框架的使用边界。

缓存管理模块和由RDD组成的DAG引擎是Spark的核心优化点。但是Spark框架缺乏有效缓存选择机制，框架没有办法识别并缓存计算过程中发生重用的数据。数据的缓存操作完全依赖于编程人员；Spark框架的缓存管理策略使用了简单的LRU策略，LRU策略只考虑时间信息，不符合Spark应用复杂的背景；因为缓存管理模块依赖于JVM虚拟机，框架和底层JVM内存释放异步执行会造成了潜在的OOM（Out of Memory）问题。

为了解决上述的三个问题。本文详细研究分析的Spark框架的原理和运行机制，并且针对Spark的原理设计实现了自动缓存管理模块、基于DAG拓扑结构缓存替换策略和容错新加强的冗余缓存清理模块。从而对Spark缓存管理系统存在的问题提出了一套解决方案。本文的主要工作如下：

\begin{enumerate}
    \item 研究分析分布式内存计算系统Spark的设计实验机制、资源管理方式和作业调度运行模式。测试并分析Spark内存管理机制的特点和问题。使用中科院大数据测试BigDataBench数据集测试Spark框架中Execution Memory、Shuffle Memory和Storage Memory内存分区的使用特点。
    \item 设计实现自动缓存系统。通过提前运行小规模数据集得到重复使用的RDD数据，之后再执行大规模数据集时自动缓存重复使用的RDD数据。同时考虑了新版本Spark中添加的动态执行特性。Spark框架在运行过程中修改执行计划时自动管理模块也会实时修改DAG图信息，保证能够做出正确的缓存决策。
    \item 设计实现基于DAG拓扑结构的缓存替换策略。该策略综合考虑了RDD的大小、计算代价以及DAG图拓扑结构等特征。综合计算得到RDD数据的优先级，发生缓存替换时淘汰优先级最低的RDD数据。
    \item 设计实现了容错新增强的冗余缓存清理模块。通过对DAG图的分析，在计算过程中自动删除部分冗余的缓存对象，提高内存空间利用率。通过保留距离当前正在计算的RDD数据为2的数据，增加了系统的容错性，从而可以兼顾系统的内存利用率和容错性。
\end{enumerate}

\keywords{分布式计算，Spark框架，缓存管理，缓存策略}% 中文关键词
%-
%-> 英文摘要
%-
\intobmk\chapter*{Abstract}% 显示在书签但不显示在目录

This paper is a help documentation for the \LaTeX{} class ucasthesis, which is  a thesis template for the University of Chinese Academy of Sciences. The main content is about how to use the ucasthesis, as well as how to write thesis efficiently by using \LaTeX{}.

\KEYWORDS{University of Chinese Academy of Sciences (UCAS), Thesis, \LaTeX{} Template}% 英文关键词
%---------------------------------------------------------------------------%

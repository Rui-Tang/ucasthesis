\chapter{总结与展望}\label{chap:guide}

\section{本文总结}

本文针对Spark框架缓存管理系统中存在的问题，本文首先对国内外研究现状以及研究目标进行了简要的分析阐述，之后在每章开始详细阐述了产生问题的原因并设计实现了解决方案，通过实验进一步验证。本文核心工作内容分为以下三点:

\begin{enumerate}
    \item 针对Spark缓存需要手动指定的问题，设计实现了自动缓存系统。通过提前运行小规模数据集得到重复使用的RDD数据，然后就可以得到DAG图结构，通过对DAG图分析就可以得到需要缓存的RDD数据，之后再执行大规模数据集时自动缓存重复使用的RDD数据。通过实验分析可以得知，自动缓存模块适合SQL查询类作业，因为这类作业的特点是不同数据规模作业的执行计划相同，所以对于数据规模越大的作业，自动缓存模块带来的额外开销占应用运行总时间越短。但是自动缓存模块不太适合迭代计算式作业，因为大规模数据迭代次数变多额外开销也会随之变大。
    \item 正对Spark默认LRU策略过于简单，不适用于复杂应用场景的问题，设计实现一种基于运行时信息和拓扑结构的缓存替换策略。综合考虑RDD数据具有的分布式存储、大小、计算代价等特征。根据RDD数据的特征以及整个作业的拓扑特征，综合计算RDD数据在缓存中的优先级，在发生缓存替换淘汰其中权值最小的RDD数据。通过实验分析可知对于小规模作业，LRU策略会更快一点，这是因为小数据集用不完缓存空间，所以缓存替换策略也体现不出效果。对于大规模数据集的SQL作业，有微小的提升效果。对于迭代时计算作业没有效果，这是因为LRU策略非常适合迭代式作业。
    \item 针对Spark系统缓存负载过高导致的OOM问题，设计实现缓存清理模块。通过分析DAG图结构，在应用执行过程中实时分析可以从缓存中删除的冗余数据，提高内存空间利用率。在清理的同时也要更具作业的拓扑信息保存一定的冗余数据，以便于作业执行出错时能够使用冗余信息迅速恢复计算。通过测试发现对于迭代计算作业，在作业开始时缓存清理模块能够减少内存使用量，但是逐渐的还是会占满所有缓存空间。缓存清理模块对于SQL查询作业效果比较好，因为SQL作业为DAG图结构，阶段性特性比较好，所以能够释放大量的内存空间。
\end{enumerate}

\section{研究展望}

本文的研究内容集中在Spark缓存管理方面，包括自动缓存功能，缓存替换策略，缓存清理方法。但是本文还存在着需要进一步深入研究的地方：

\begin{enumerate}
    \item 自动缓存模块需要通过重复运行应用，得到DAG图结构进行分析才可以做出自动缓存决策。在实际工程实现方面需要修改应用代码才可以实现这个功能。并且对迭代时计算来说，自动缓存带来的额外开销会随着迭代次数变多而随之变大。后续研究中可以探索其他自动缓存功能的实现方式，从而可以在不影响应用执行效率的前提下简化编程人员编程。
    \item 对于OOM问题，可以继续探索新的解决方案。比如可以修改JVM虚拟机和框架的内存管理模块，将框架的缓存回收操作与JVM垃圾回收同步，并且在内存超限时自动申请对外内存，这样就可以避免因为内存使用超限导致的进程退出问题
\end{enumerate}